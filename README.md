# We-rate-dogs-data-wrangling-project-with-python

This is a consise analysis of tweet archive of Twitter user @dog_rates, also known as WeRateDogs rating dogs using jupyter notebooks, python and its libraries. In the data analysis methodology, datasets were sufficiently wrangled, analysed and visualized for proper communication.

To begin the wrangling process, data to be used for analysis was initially gathered from three sources using three different approaches. After gathering all our data and creating our datasets, each dataset was rigously assessed employing both programmatic assessment and visual assessment to quality-check the credibility of our datasets to be utilized for analysis. The assessment was done to check for data issues with regard to completeness, validity, accuracy, and consistency.

After visually and programmatically assessing the datasets using pandas functions and methods, all issues raised or noted/documented during assessments was prepared for cleaning to make the dataset viable for effective analysis and visualization.

The cleaned/revamped datasets were stored into a final csv file, twitter_archive_master.csv for further analysis and visualization. Insights were lastly drawn from my analysis and visualization to conclude the project.

**It is to be noted that the order of methodology was subjected to changes since data reiterations to further refine my final dataset was done at later stages of the wrangling process.

## Gathering
In the gathering stage, three datasets were gathered from different sources employing different approaches. The datasets gathered are as follows:

Twitter archive file: This csv file/data was manually downloaded using following link source provided by udacity: twitter_archive_enhanced.csv. This was subsequently writen into pandas dataframe under the variable name df_doggo.
The tweet image predictions : This gives details of the dog type predicted in each tweet according to a neural network. The file (image_predictions.tsv) is hosted on Udacity's servers and was downloaded programmatically using the python Requests library and accessing following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv. This was then written into a pandas dataframe under the variable name twitter_image_predict.
tweet_json file: Json data was gathered/read from a tweet_json.txt file line by line, generated by udacity using the tweet IDs in the WeRateDogs Twitter archive; employing Twitter API to query each tweet's JSON data. Each tweet's JSON data was written to its own line. The .txt file was read line by line into a pandas DataFrame under the variable name my_tweet_json with atleast tweet ID, retweet count, and favorite count columns present.

## Assessing
Visual assessment and programmatic assessment were carried on the gathered datasets to check for quality issues with regard to completeness, validity, accuracy, consistency and tidiness issue with regard to the structure of the dataset to be used for analysis and visualization. In programmatically assessing the datasets, pandas functions/methods such .info(), .head(), .value_counts(), .duplicated(), .dtypes, .isna(), and .isnull() were utilized.

Overall, eight (8) quality issues and two (2) tidiness issues were documented for cleaning. It is to be noted that cleaning iterations were further done to refine the dataset later on in the project.

## Cleaning
In this section, all issues documented during assessments were addressed and sufficiently cleaned. Before cleaning the datasets, copies of the original datasets were created using the pandas functions .copy().

The process for cleaning was initially clearly defined and further put into code. Verification was done on the revamped data by testing using pandas functions/methods like .head(), .info().

## Storing Data
In this section of the project, the cleaned and combined/merged master dataframe twitter_archive_master.csv is stored using the pandas fuctions .to_csv()

## Analysis and Visualization
In the last section of the project, the master dataframe twitter_archive_master.csv was utilized for our final analysis and comunications.

Three(3) insights were established from my analysis being supported by two visualizations. The insights noted from the analysis and visualization were:

Japanese spaniel has the lowest average dog rating and clumber has the highest dog rating.

The golden retriever was the most common dog rated in the master dataset followed by labrador retriever.

Predicted dog types with low rating counts showed low average ratings.

Saluki and Brabancon_griffon had the highest and lowest average favorite counts respectively, for all the predicted dog types.
